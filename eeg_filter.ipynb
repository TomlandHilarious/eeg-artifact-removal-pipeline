{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic data\n",
    "torch.manual_seed(42)\n",
    "n_samples = 5000\n",
    "sample_rate = 256\n",
    "time = torch.arange(0, n_samples) / sample_rate\n",
    "base_signal = 0.1 * torch.randn(n_samples)\n",
    "blink_indices = torch.randint(0, n_samples, size = (5,))\n",
    "for idx in blink_indices:\n",
    "    start = idx\n",
    "    end = min(idx + 50, n_samples)\n",
    "    base_signal[start:end] += torch.linspace(3, 0, end - start)\n",
    "eeg_signal = base_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: SSA embedding of the raw EEG signal\n",
    "def ssa_embedding(signal, window_size=256):\n",
    "    x = torch.as_tensor(signal, dtype=torch.float32)\n",
    "    N = x.shape[0]\n",
    "    X = x.unfold(dimension=0, size=window_size, step=1)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory matrix shape: torch.Size([4745, 256])\n"
     ]
    }
   ],
   "source": [
    "X = ssa_embedding(eeg_signal, 256)\n",
    "print(\"Trajectory matrix shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2: feature extraction (four time domain features)\n",
    "def extract_features(ssa_embedding: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    ssa_embedding: a 2D tensor of shape (L, K),\n",
    "                   where L is window_size and K is the number of columns\n",
    "    Returns a 2D tensor of shape (4, K),\n",
    "    with rows = [energy, mobility, kurtosis, peak2peak]\n",
    "    and each column corresponds to the features of ssa_embedding[:, k].\n",
    "    \"\"\"\n",
    "    def compute_energy(x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        energy feature\n",
    "        \"\"\"\n",
    "        return torch.sum(x**2)\n",
    "\n",
    "    def hjorth_mobility(x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        hjorty mobility\n",
    "        \"\"\"\n",
    "        dx = x[1:] - x[:-1]\n",
    "        var_x = torch.var(x, unbiased=True)\n",
    "        var_dx = torch.var(dx, unbiased=True)\n",
    "        if var_x == 0:\n",
    "            return 0.0\n",
    "        mobility = torch.sqrt(var_dx / var_x)\n",
    "        return mobility\n",
    "\n",
    "    def kurtosis(x: torch.Tensor, excess: bool = False) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        kurtosis, could either use raw or adjusted\n",
    "        \"\"\"\n",
    "        x = x.to(dtype=torch.float32)\n",
    "        mean_x = torch.mean(x)\n",
    "        var_x = torch.var(x, unbiased=True)\n",
    "\n",
    "        if var_x == 0:\n",
    "            return torch.tensor(0.0)\n",
    "        \n",
    "        fourth_moment = torch.mean((x - mean_x) **4)\n",
    "        raw_kurtosis = fourth_moment / (var_x**2)\n",
    "        \n",
    "        if excess:\n",
    "            return raw_kurtosis - 3\n",
    "        else:\n",
    "            return raw_kurtosis\n",
    "        \n",
    "    def peak_to_peak(x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        min max diff\n",
    "        \"\"\"\n",
    "        return torch.max(x) - abs(torch.min(x))\n",
    "\n",
    "    L, K = ssa_embedding.shape\n",
    "    features = torch.zeros((4, K), dtype=torch.float32)\n",
    "    for k in range(K):\n",
    "        col = ssa_embedding[:, k]\n",
    "        e = compute_energy(col)\n",
    "        m = hjorth_mobility(col)\n",
    "        ku = kurtosis(col)\n",
    "        p2p = peak_to_peak(col)\n",
    "        \n",
    "        # save into resulting matrix\n",
    "        features[0, k] = e\n",
    "        features[1, k] = m\n",
    "        features[2, k] = ku\n",
    "        features[3, k] = p2p\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = extract_features(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Perform k-means clustering on the columns of feature_matrix.\n",
    "def k_means_clustering(feature_matrix: torch.Tensor, num_clusters: int):\n",
    "    feature_matrix_np = feature_matrix.T.cpu().numpy().astype(np.float32)\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    labels = kmeans.fit_predict(feature_matrix_np)\n",
    "    # Centroids: shape (num_clusters, num_features)\n",
    "    centers = kmeans.cluster_centers_\n",
    "    return labels, centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, centers = k_means_clustering(feature_matrix, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: restructure the original ssa embedding matrix\n",
    "def ssa_diagonal_average(X_bar: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Diagonal-average (Hankelize) the L x K matrix X_bar into a 1D signal s\n",
    "    of length (L + K - 1).\n",
    "    \"\"\"\n",
    "    L, K = X_bar.shape\n",
    "    N = L + K - 1\n",
    "\n",
    "    # prepare tensors\n",
    "    s = torch.zeros(N, dtype=X_bar.dtype, device=X_bar.device)\n",
    "    count = torch.zeros(N, dtype=X_bar.dtype, device=X_bar.device)\n",
    "\n",
    "    for r in range(L):\n",
    "        for c in range(K):\n",
    "            idx = r + c\n",
    "            s[idx] += X_bar[r, c]\n",
    "            count[idx] += 1\n",
    "    \n",
    "    # only divide at non-zero position\n",
    "    mask = (count != 0)\n",
    "    s[mask] /= count[mask]\n",
    "    return s\n",
    "\n",
    "def reconstruct_signals(X:torch.Tensor, labels:np.ndarray, num_clusters:int):\n",
    "    L, K = X.shape\n",
    "    def create_cluster_matrix(X:torch.Tensor, cluster_idx:int):\n",
    "        \"\"\"\n",
    "        Creates the cluster-specific matrix X̄ᵢ (shape L x K)\n",
    "        by copying columns from X if labels[j] == cluster_idx,\n",
    "        else putting 0 in that column.\n",
    "        \"\"\"\n",
    "        X_i = torch.zeros_like(X)\n",
    "        for j in range(K):\n",
    "            if labels[j] == cluster_idx:\n",
    "                X_i[:, j] = X[:, j]\n",
    "        return X_i\n",
    "\n",
    "        \n",
    "    # Create and reconstruct each cluster\n",
    "    signals = []\n",
    "    for cluster_idx in range(num_clusters):\n",
    "        # 1) Build X̄ᵢ\n",
    "        X_i = create_cluster_matrix(X, cluster_idx)\n",
    "        # 2) Diagonal-average => 1D signal\n",
    "        s_i = ssa_diagonal_average(X_i)\n",
    "        signals.append(s_i)\n",
    "\n",
    "    return signals\n",
    "signals = reconstruct_signals(X, labels, 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5-7\n",
    "def fractal_sevcik(signal:torch.Tensor) -> float:\n",
    "    \"\"\"Sevcik Fractal Dimension (SFD) referred by the original paper, \n",
    "        adapted from \n",
    "        https://github.com/neuropsychology/NeuroKit/blob/master/neurokit2/complexity/fractal_sevcik.py\n",
    "    \"\"\"\n",
    "    n = signal.shape[0]\n",
    "    s_min = torch.min(signal)\n",
    "    s_max = torch.max(signal)\n",
    "\n",
    "    # 1) Normalize the signal (new range to [0, 1])\n",
    "    y_ = (signal - s_min) / (s_max - s_min)\n",
    "    # 2) Derive x* and y* (y* is actually the normalized signal)\n",
    "    x_ = torch.linspace(0, 1, steps=n, dtype=torch.float32, device=signal.device)\n",
    "    # 3) Compute L (because we use np.diff, hence n-1 below)\n",
    "    dy = y_[1:] - y_[:-1]\n",
    "    dx = x_[1:] - x_[:-1]\n",
    "    dist = torch.sqrt(dx**2 + dy**2)\n",
    "    L = torch.sum(dist)\n",
    "    # 4. Compute the fractal dimension (approximation)\n",
    "    sfd = 1.0 + torch.log(L) / torch.log(torch.tensor(2.0 * (n - 1), device=signal.device))\n",
    "    return float(sfd.item())\n",
    "\n",
    "def ssa_decomposition(A_hat:torch.Tensor):\n",
    "    # 1) SVD of A_hat\n",
    "    # U: (M, M), S: (min(M,K),), Vt: (K, K)\n",
    "    U, S, Vt = torch.linalg.svd(A_hat, full_matrices=False)\n",
    "    A_list = []\n",
    "    for i in range(S.shape[0]):\n",
    "        sigma_i = S[i]\n",
    "        u_i = U[:, i]\n",
    "        v_i = Vt[i,:]\n",
    "        A_i = sigma_i * (u_i.unsqueeze(1) @ v_i.unsqueeze(0))\n",
    "        A_list.append(A_i)\n",
    "    \n",
    "    return A_list, S\n",
    "def ssa_grouping(A_list, singular_values, threshold=0.01):\n",
    "    sigmas = singular_values.float()\n",
    "    lambdas = sigmas**2\n",
    "\n",
    "    total_lambda = torch.sum(lambdas)\n",
    "    if total_lambda <= 0:\n",
    "        return torch.zeros_like(A_list[0]), []\n",
    "    \n",
    "    ratios = lambdas / total_lambda\n",
    "\n",
    "    kept_indices = []\n",
    "    for i in range(len(A_list)):\n",
    "        if ratios[i].item() > threshold:\n",
    "            kept_indices.append(i)\n",
    "        \n",
    "    if len(kept_indices) == 0:\n",
    "        A_sum = torch.zeros_like(A_list[0])\n",
    "    else:\n",
    "        A_sum = A_list[kept_indices[0]].clone()\n",
    "        for idx in kept_indices[1:]:\n",
    "            A_sum += A_list[idx]\n",
    "    return A_sum, kept_indices\n",
    "\n",
    "def refine_artifact_with_ssa(\n",
    "        artifact_signal: torch.Tensor,\n",
    "        window_size: int,\n",
    "        grouping_threshold: float):\n",
    "    \"\"\"\n",
    "    Steps 8 & 9:\n",
    "      Step 8: Apply SSA to the artifact_signal to remove EEG remnants.\n",
    "              (pipeline: embed -> decompose -> group -> FD)\n",
    "    \"\"\"\n",
    "    artifact_signal = ssa_embedding(artifact_signal, window_size)\n",
    "    decomposed_artifact_signals, singular_values = ssa_decomposition(artifact_signal)\n",
    "    A_sum, _ = ssa_grouping(decomposed_artifact_signals, singular_values, grouping_threshold)\n",
    "    blink_artifact = ssa_diagonal_average(A_sum)\n",
    "    return blink_artifact\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_blink_artifact(cluster_signals,\n",
    "                          eeg_signal: torch.Tensor,\n",
    "                          fd_threshold:float):\n",
    "    \"\"\"\n",
    "    Identify and remove eye-blink artifact from EEG by:\n",
    "      1) Computing FD for each cluster signal,\n",
    "      2) Selecting those with FD <= fd_threshold (blink-like),\n",
    "      3) Summing those to form the blink estimate,\n",
    "      4) Subtracting from the original EEG.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cluster_signals : list[torch.Tensor]\n",
    "        A list of length L, where each element is a 1D PyTorch tensor\n",
    "        of the same length as eeg_signal. These are the signals reconstructed\n",
    "        from Step 4 (i.e., from diagonal averaging of each cluster).\n",
    "    eeg_signal : torch.Tensor\n",
    "        The original 1D EEG recording (contaminated by blink).\n",
    "    fd_threshold : float\n",
    "        The preset fractal dimension threshold. Any signal with FD <= this\n",
    "        is considered blink-artifact.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cleaned_eeg : torch.Tensor\n",
    "        The artifact-corrected EEG (same shape as eeg_signal).\n",
    "    blink_estimate : torch.Tensor\n",
    "        The summed blink-artifact signal (same shape as eeg_signal).\n",
    "    fd_values : list[float]\n",
    "        The FD values for each cluster signal, in the same order as cluster_signals.\n",
    "    \"\"\"\n",
    "    # Step 5: Compute FD & sum blink components\n",
    "    eeg_signal = eeg_signal.flatten()\n",
    "    L = eeg_signal.shape[0]\n",
    "    fd_values = []\n",
    "    blink_components = []\n",
    "    for signal in cluster_signals:\n",
    "        fd_val = fractal_sevcik(signal)\n",
    "        fd_values.append(fd_val)\n",
    "        if fd_val <= fd_threshold:\n",
    "            blink_components.append(signal)\n",
    "    if len(blink_components) == 0:\n",
    "        a_r = torch.zeros_like(eeg_signal)\n",
    "    else:\n",
    "        a_r = blink_components[0].clone()\n",
    "        for b_idx in range(1, len(blink_components)):\n",
    "            a_r += blink_components[b_idx]\n",
    "\n",
    "    # Step 6: Convert a_r to a binary template a_b (nonzero -> 1, zero -> 0)\n",
    "    a_b = (a_r != 0).float()\n",
    "    # Step 7: Multiply the binary artifact template by the original EEG x\n",
    "    #         => blink_artifact = a_b * x\n",
    "    blink_artifact = a_b * eeg_signal\n",
    "    # Step 8: refine the artifact with SSA\n",
    "    blink_artifact = refine_artifact_with_ssa(blink_artifact, 256, 0.01)\n",
    "    # Step 9: subtract the artifact from the contaminated signal\n",
    "    cleaned_eeg = eeg_signal - blink_artifact\n",
    "    \n",
    "    return cleaned_eeg, blink_artifact, fd_values\n",
    "\n",
    "cleaned_eeg, blink_est, fd_vals = remove_blink_artifact(signals,\n",
    "                                                        eeg_signal,\n",
    "                                                        1.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1927,  0.1487,  0.0901,  ..., -0.1071,  0.0778, -0.1770])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_eeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "av",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
